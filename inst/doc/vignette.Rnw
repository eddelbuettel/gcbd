
%% use JSS class but for now with nojss option
\documentclass[nojss,article]{jss}
\usepackage{float}

<<echo=FALSE,print=FALSE>>=
options(width=50)
library(gcbd)
gcbd.version <- packageDescription("gcbd")$Version
gcbd.date <- packageDescription("gcbd")$Date
# dput(brewer.pal(5, "Set1"))
cols <- c("#E41A1C", "#377EB8", "#4DAF4A", "#984EA3", "#FF7F00")
# dput(brewer.pal(8,"Paired"))
paircols <- c("#A6CEE3", "#1F78B4", "#B2DF8A", "#33A02C", "#FB9A99", "#E31A1C", "#FDBF6F", "#FF7F00")
@

\author{Dirk Eddelbuettel\\Debian Project} % \And Second Author\\Plus Affiliation}
\title{Benchmarking single- and multi-core BLAS implementations and GPUs for use with \proglang{R}}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Dirk Eddelbuettel} % , Second Author} %% comma-separated
\Plaintitle{Benchmarking Single- and Multi-Core BLAS Implementaions and GPUs for Use with R}
\Shorttitle{Benchmarking BLAS and GPUs for Use with R}

%% an abstract and keywords
\Abstract{
  \noindent
  We provide timings for common linear algebra subroutines. Several BLAS
  (Basic Linear Algrebra Subprograms) are compared. The first is the
  unoptimised reference BLAS which provides a baseline to measure
  against. Second is the Atlas tuned BLAS, configured for single-threaded
  mode. Third is the optimised and multi-threaded Goto BLAS. Fourth is the
  multithreaded-BLAS contained in the commercial Intel MKL package. We also use two
  GPU-based implementations: \pkg{gputools} as well as \pkg{magma}.

  Several key computations are compared: matrix multiplication, QR
  decomposition and SVD decomposition.

%  This paper corresponds to gcbd version \Sexpr{gcbd.version}.
}
\Keywords{blas, atlas, goto, mkl, gpu}
\Plainkeywords{blas, atlas, goto, mkl, gpu} %% without formatting
%% at least one keyword must be supplied

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{13}
%% \Issue{9}
%% \Month{September}
%% \Year{2004}
%% \Submitdate{2004-09-29}
%% \Acceptdate{2004-09-29}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
  Dirk Eddelbuettel \\
  Debian Project \\
  River Forest, IL, USA\\
  E-mail: \email{edd@debian.org}\\
  URL: \url{http://dirk.eddelbuettel.com}
}
%% It is also possible to add a telephone and fax number
%% before the e-mail in the following format:
%% Telephone: +43/1/31336-5053
%% Fax: +43/1/31336-734

%% for those who use Sweave please include the following line (with % symbols):
%% need no \usepackage{Sweave.sty}

%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}
\SweaveOpts{engine=R,eps=FALSE,echo=FALSE}
%\VignetteIndexEntry{BLAS and GPU Benchmarking}
%\VignetteDepends{gputools,magma
%\VignetteKeywords{blas,gpu,atlas,mkl,goto}
%\VignettePackage{gcbd}

%% include your article here, just as usual
%% Note that you should use the \pkg{}, \proglang{} and \code{} commands.

\section[Introduction]{Introduction}

Analysts are often eager to reap the maximum performance from their
computing platform.  A popular suggestion in recent years has been to
consider \textsl{optimised} (in a sense we will define further below) basic
linear algebra subprograms (BLAS).  These are included with some analysis
platforms, or readily available for others. [TODO R Inst Admin reference]

Among the BLAS implementations, several popular choices have emerged. Atlas
(an acronym for \textsl{automatically tuned linear algebra system} is popular
as it has shown good performance. It is also licensed in such a way that it
permits distributors to include it in their products.  Another popular BLAS
implementation is Goto BLAS (which is named after its main developer, Kazushige
Goto). While `free to use', its license does not permit redistribution.
Lastly, the Intel MKL, a commercial product, also includes an optimised BLAS
library.

A recent addition to the toolchain of high-performance computing are
graphical processing units (GPUs).  Originally designed for optmised
single-precision arithmetic to accelerate computing as performed by graphics
cards, these devices are increasingly used in numerical analysis.  Earlier
criticism of insufficient floating-point precisions (IEEE standard; reference
?) or severe performance penalties for double-precision calculation are being
addressed by the newest models. Dependence on particular vendors remains a
concern which NVidia's CUDA toolkit currently still the development choice
where the newer OpenCL standard may become a more generic successor.

What has been lacking is comparison of effective performance of these
alternative.  This paper works towards answering answer this question.
In the next section, the technical background is discussed before the
implementation of our approach is outlined. We then provide our results in
the following section. A summary concludes.

\section[Test Implementation]{Background and Implementation}

\subsection{Background}

Basic Linear Algrebra Subprograms (BLAS) provide an Application Programming
Interface (API).  For a givem task as, say, a multiplication of two
conformant matrices, an interface is described via a function
declaration. The actual implementation then becomes interchangeable and can
be supplied by different approaches.  This is one of the fundamental code
design features we are using here to benchmark the difference in performance
from different implementations.

A second key aspect is the difference between static and shared linking.  In
static linking, object code is copied from the uderlying library and copied
into the resulting executable.  This has several key implications. First, it
the executable larger due to the copy of code. Second, it makes it marginally
faster as the library code is present and additional lookup and subsequent
redirect has to be performed (and the amount of this performance penalty is
the subject of near endless debate). Third, it make the program more robust
as fewer external dependencies are required.  However, this last point also
has a downside: no changes in the underlying library will be reflected in the
binary unless a new build is executed.  Shared library builds, on the other
hand, result in smaller binaries that may run marginally slower -- but can
make use of different libraries without a rebuild.  That last feature is key
here.

Because of both the standardised interface of the BLAS, and the fact that we
have several alternative implementations at out disposal, we can readily
switch between these alternatives. This makes use of a package mechanism
used by the Linux distribution we employ. However, a simpler (yet less
robust) approach would also be available. This technical aspect is discussed
further below.

The first available BLAS implementation stems from the original unoptimised
code on Netlib. On Debian-based systems, it is provided by the (source)
packages \pkg{blas} and \pkg{lapack}. It is commonly referred to as
'reference BLAS' (and we will use 'ref' as a shorthand) as it provides a
refernce implementation.

The second available BLAS implementation is part of the Intel MKL. This is
commonly a commercial package. However, Ubuntu release 9.10 (``karmic'')
contains a set of packages sponsored by Revolution Analytics which comprises
the Intel MKL in a setup directly useable by \proglang{R}. We will use these
packages here as a first set of optimised BLAS.

The third BLAS implementation is provided by the Goto BLAS. Upon
registration, these are freely available from the University of Texas, albeit
under license that prohibits redistribution.  This prevents inclusion into
popular Liux distributions.  However, the ISM in Japan provides a `helper
package' which, given the required registration information, downloads and
compiles the Goto BLAS in such a manner that another binary Debian package
results.  This allow to use the package as a third BLAS alternative.

The first \proglang{R} extension for graphics-processing units was provided
by the \pkg{gputools} package. It provides a number of functions which use
the GPU instead of the CPU, providing a noticeable speed-up for `large
enough' problems.  Because data has to be transferred from the CPU to the
GPU, a fixed cost in communications has to be borne by every invocation of
the GPU.  For sizeable problems, this cost can be outweighed by the benefits
of the massively parallel GPU computation.  Exactly where the indifference
point lies beyond which GPU computing has an advantage is unfortunately
dependent on the particular problem and algorithm as well as the given
hardware and software combination.  T

A very recent addition to the set of \proglang{R} packages is \pkg{magma}
which interfaces the eponymous library by Dongerra et al (which we will
capitalize to distinguish it from the \proglang{R} package).

Mention R has to be built with shared lib and external blas to allow
switching as we do here

Describe Debian install / purge of packages

Mention hardware impact, show baseline results on different platforms?

\section[Results]{Results}

<<print=FALSE>>=
dbcon <- dbConnect(dbDriver("SQLite"), dbname=system.file("sql", "gcbd.sqlite", package="gcbd"))
i7 <- dbGetQuery(dbcon, 'select * from benchmark where host="max" order by nobs')
xeon <- dbGetQuery(dbcon, 'select * from benchmark where host="xeon_X5570" order by nobs')
invisible(dbDisconnect(dbcon))
D <- subset(i7[,-c(1:2,5)], type=="matmult")
@

\subsection{BLAS Comparison}

\subsubsection{Matrix Multiplication: i7 with GPU}

\setkeys{Gin}{width=0.99\textwidth}
\begin{figure}[H]
  \centering
<<fig=TRUE,height=6,width=12>>=
D <- subset(i7[,-c(1:2,5)], type=='matmult')
op <- par(mfrow=c(1,2))
matplot(x=D[,"nobs"], y=D[,c("ref","atlas","mkl","gotob","gpu")], type='l', lty=1, col=cols,
        xlab="Matrix dimension", ylab="Time in seconds", main="Matrix Multiplication")
legend("topleft", legend=c("Ref","Atlas","MKL","Goto","GPU"), bty="n", col=cols, lty=1)
matplot(x=D[,"nobs"], y=D[,c("ref","atlas","mkl","gotob","gpu")], type='l', lty=1, col=cols,
        xlab="Matrix dimension", ylab="Time in seconds (in logs)", main="Matrix Multiplication", log="y")
legend("bottomright", legend=c("Ref","Atlas","MKL","Goto","GPU"), bty="n", col=cols, lty=1)
par(op)
@
\end{figure}

\subsubsection{Matrix Multiplication: Xeon}

\begin{figure}[H]
  \centering
<<fig=TRUE,height=6,width=12>>=
D <- subset(xeon[,-c(1:2,5)], type=='matmult')
op <- par(mfrow=c(1,2))
matplot(x=D[,"nobs"], y=D[,c("ref","atlas","mkl","gotob")], type='l', lty=1, col=cols,
        xlab="Matrix dimension", ylab="Time in seconds", main="Matrix Multiplication")
legend("topleft", legend=c("Ref","Atlas","MKL","Goto"), bty="n", col=cols, lty=1)
matplot(x=D[,"nobs"], y=D[,c("ref","atlas","mkl","gotob")], type='l', lty=1, col=cols,
        xlab="Matrix dimension", ylab="Time in seconds (in logs)", main="Matrix Multiplication", log="y")
legend("bottomright", legend=c("Ref","Atlas","MKL","Goto"), bty="n", col=cols, lty=1)
par(op)
@
\end{figure}


\subsubsection{QR Decomposition: i7 with GPU}

\begin{figure}[H]
  \centering
<<fig=TRUE,height=6,width=12>>=
D <- subset(i7[,-c(1:2,5)], type=='qr')
op <- par(mfrow=c(1,2))
matplot(x=D[,"nobs"], y=D[,c("ref","atlas","mkl","gotob","gpu")], type='l', lty=1, col=cols,
        xlab="Matrix dimension", ylab="Time in seconds", main="QR Decomposition")
legend("topleft", legend=c("Ref","Atlas","MKL","Goto","GPU"), bty="n", col=cols, lty=1)
matplot(x=D[,"nobs"], y=D[,c("ref","atlas","mkl","gotob","gpu")], type='l', lty=1, col=cols, log="y",
        xlab="Matrix dimension", ylab="Time in seconds (in logs)", main="QR Decomposition")
legend("bottomright", legend=c("Ref","Atlas","MKL","Goto","GPU"), bty="n", col=cols, lty=1)
par(op)
@
\end{figure}

\subsubsection{QR Decomposition: Xeon}

\begin{figure}[H]
  \centering
<<fig=TRUE,height=6,width=12>>=
D <- subset(xeon[,-c(1:2,5)], type=='qr')
op <- par(mfrow=c(1,2))
matplot(x=D[,"nobs"], y=D[,c("ref","atlas","mkl","gotob")], type='l', lty=1, col=cols,
        xlab="Matrix dimension", ylab="Time in seconds", main="QR Decomposition")
legend("topleft", legend=c("Ref","Atlas","MKL","Goto"), bty="n", col=cols, lty=1)
matplot(x=D[,"nobs"], y=D[,c("ref","atlas","mkl","gotob")], type='l', lty=1, col=cols,
        xlab="Matrix dimension", ylab="Time in seconds (in logs)", main="QR Decomposition", log="y")
legend("bottomright", legend=c("Ref","Atlas","MKL","Goto"), bty="n", col=cols, lty=1)
par(op)
@
\end{figure}

\subsubsection{SVD Decomposition: i7 with GPU}

\begin{figure}[H]
  \centering
<<fig=TRUE,height=6,width=12>>=
D <- subset(i7[,-c(1:2,5)], type=='svd')
op <- par(mfrow=c(1,2))
matplot(x=D[,"nobs"], y=D[,c("ref","atlas","mkl","gotob","gpu")], type='l', lty=1, col=cols,
        xlab="Matrix dimension", ylab="Time in seconds", main="SVD Decomposition")
legend("topleft", legend=c("Ref","Atlas","MKL","Goto","GPU"), bty="n", col=cols, lty=1)
matplot(x=D[,"nobs"], y=D[,c("ref","atlas","mkl","gotob","gpu")], type='l', lty=1, col=cols, log="y",
        xlab="Matrix dimension", ylab="Time in seconds (in logs)", main="SVD Decomposition")
legend("bottomright", legend=c("Ref","Atlas","MKL","Goto","GPU"), bty="n", col=cols, lty=1)
par(op)
@
\end{figure}

\subsubsection{SVD Decomposition: Xeon}

\begin{figure}[H]
  \centering
<<fig=TRUE,height=6,width=12>>=
D <- subset(xeon[,-c(1:2,5)], type=='svd')
op <- par(mfrow=c(1,2))
matplot(x=D[,"nobs"], y=D[,c("ref","atlas","mkl","gotob")], type='l', lty=1, col=cols,
        xlab="Matrix dimension", ylab="Time in seconds", main="SVD Decomposition")
legend("topleft", legend=c("Ref","Atlas","MKL","Goto"), bty="n", col=cols, lty=1)
matplot(x=D[,"nobs"], y=D[,c("ref","atlas","mkl","gotob")], type='l', lty=1, col=cols,
        xlab="Matrix dimension", ylab="Time in seconds (in logs)", main="SVD Decomposition", log="y")
legend("bottomright", legend=c("Ref","Atlas","MKL","Goto"), bty="n", col=cols, lty=1)
par(op)
@
\end{figure}


\subsection{Magma: GPU and BLAS combined}

\begin{figure}[H]
  \centering
<<fig=TRUE,height=6,width=12>>=
D <- subset(i7[,-c(1:2,5)], type=='matmult')
op <- par(mfrow=c(1,2))
matplot(x=D[,"nobs"], y=D[,c("atlas","magmaAtlas","gotob","magmaGoto", "mkl", "magmaMkl")],
        type='l', lty=1, col=paircols,
        xlab="Matrix dimension", ylab="Time in seconds", main="Matrix Multiplication")
legend("topleft", legend=c("Atlas","Atlas/Magma", "Goto", "Goto/Magma", "MKL", "MKL/Magma"),
       bty="n", col=paircols, lty=1)
matplot(x=D[,"nobs"], y=D[,c("atlas","magmaAtlas","gotob","magmaGoto", "mkl", "magmaMkl")],
        type='l', lty=1, col=paircols, log="y",
        xlab="Matrix dimension", ylab="Time in seconds (in logs)", main="Matrix Multiplication")
legend("bottomright",
       legend=c("Atlas","Atlas/Magma", "Goto", "Goto/Magma", "MKL", "MKL/Magma"),
       bty="n", col=paircols, lty=1)
par(op)
@
\end{figure}

\begin{figure}[H]
  \centering
<<fig=TRUE,height=6,width=12>>=
D <- subset(i7[,-c(1:2,5)], type=='qr')
op <- par(mfrow=c(1,2))
matplot(x=D[,"nobs"], y=D[,c("atlas","magmaAtlas","gotob","magmaGoto", "mkl", "magmaMkl")],
        type='l', lty=1, col=paircols,
        xlab="Matrix dimension", ylab="Time in seconds", main="QR Decomposition")
legend("topleft", legend=c("Atlas","Atlas/Magma", "Goto", "Goto/Magma", "MKL", "MKL/Magma"),
       bty="n", col=paircols, lty=1)
matplot(x=D[,"nobs"], y=D[,c("atlas","magmaAtlas","gotob","magmaGoto", "mkl", "magmaMkl")],
        type='l', lty=1, col=paircols, log="y",
        xlab="Matrix dimension", ylab="Time in seconds (in logs)", main="QR Decomposition")
legend("bottomright",
       legend=c("Atlas","Atlas/Magma", "Goto", "Goto/Magma", "MKL", "MKL/Magma"),
       bty="n", col=paircols, lty=1)
par(op)
@
\end{figure}

\begin{figure}[H]
  \centering
<<fig=TRUE,height=6,width=12>>=
D <- subset(i7[,-c(1:2,5)], type=='svd')
op <- par(mfrow=c(1,2))
matplot(x=D[,"nobs"], y=D[,c("atlas","magmaAtlas","gotob","magmaGoto", "mkl", "magmaMkl")],
        type='l', lty=1, col=paircols,
        xlab="Matrix dimension", ylab="Time in seconds", main="SVD Decomposition")
legend("topleft", legend=c("Atlas","Atlas/Magma", "Goto", "Goto/Magma", "MKL", "MKL/Magma"),
       bty="n", col=paircols, lty=1)
matplot(x=D[,"nobs"], y=D[,c("atlas","magmaAtlas","gotob","magmaGoto", "mkl", "magmaMkl")],
        type='l', lty=1, col=paircols, log="y",
        xlab="Matrix dimension", ylab="Time in seconds (in logs)", main="SVD Decomposition")
legend("bottomright",
       legend=c("Atlas","Atlas/Magma", "Goto", "Goto/Magma", "MKL", "MKL/Magma"),
       bty="n", col=paircols, lty=1)
par(op)
@
\end{figure}


\begin{figure}[H]
  \centering
<<fig=TRUE,height=6,width=12>>=
op <- par(mfrow=c(1,3))
D <- subset(i7[,-c(1:2,5)], type=='matmult')
N <- cbind(D[,"nobs"],
           D[,"ref"]/D[,"atlas"],
           D[,"ref"]/D[,"magmaAtlas"],
           D[,"ref"]/D[,"gotob"],
           D[,"ref"]/D[,"magmaGoto"],
           D[,"ref"]/D[,"mkl"],
           D[,"ref"]/D[,"magmaMkl"],
           D[,"ref"]/D[,"gpu"])
matplot(x=D[,"nobs"], y=N[,-1],
        type='l', lty=1, col=paircols, #pch=".",
        xlab="Matrix dimension", ylab="Performance relative to Ref.BLAS",
        main="Matrix Multiplication:\nRatio of Reference BLAS to given BLAS")
legend("bottomright",
       legend=c("Atlas","Atlas/Magma", "Goto", "Goto/Magma", "MKL", "MKL/Magma", "GPU"),
       bty="n", col=paircols, lty=1)

D <- subset(i7[,-c(1:2,5)], type=='qr')
N <- cbind(D[,"nobs"],
           D[,"ref"]/D[,"atlas"],
           D[,"ref"]/D[,"magmaAtlas"],
           D[,"ref"]/D[,"gotob"],
           D[,"ref"]/D[,"magmaGoto"],
           D[,"ref"]/D[,"mkl"],
           D[,"ref"]/D[,"magmaMkl"],
           D[,"ref"]/D[,"gpu"])
matplot(x=D[,"nobs"], y=N[,-1],
        type='l', lty=1, col=paircols, #pch=".",
        xlab="Matrix dimension", ylab="Performance relative to Ref.BLAS",
        main="QR Decomposition:\nRatio of Reference BLAS to given BLAS")
legend("bottomright",
       legend=c("Atlas","Atlas/Magma", "Goto", "Goto/Magma", "MKL", "MKL/Magma", "GPU"),
       bty="n", col=paircols, lty=1)

D <- subset(i7[,-c(1:2,5)], type=='svd')
N <- cbind(D[,"nobs"],
           D[,"ref"]/D[,"atlas"],
           D[,"ref"]/D[,"magmaAtlas"],
           D[,"ref"]/D[,"gotob"],
           D[,"ref"]/D[,"magmaGoto"],
           D[,"ref"]/D[,"mkl"],
           D[,"ref"]/D[,"magmaMkl"],
           D[,"ref"]/D[,"gpu"])
matplot(x=D[,"nobs"], y=N[,-1],
        type='l', lty=1, col=paircols, #pch=".",
        xlab="Matrix dimension", ylab="Performance relative to Ref.BLAS",
        main="SVD Decomposition:\nRatio of Reference BLAS to given BLAS")
legend("bottomright",
       legend=c("Atlas","Atlas/Magma", "Goto", "Goto/Magma", "MKL", "MKL/Magma", "GPU"),
       bty="n", col=paircols, lty=1)

@
\end{figure}

\section[Summary]{Summary}

\end{document}
